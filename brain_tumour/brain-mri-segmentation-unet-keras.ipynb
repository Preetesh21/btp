{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import necessary libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport cv2\nfrom glob import glob\nimport sys\nimport os\nimport glob\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport cv2\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid import ImageGrid\n\nplt.style.use(\"dark_background\")\nimport tensorflow as tf\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D\nfrom tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:49:36.678695Z","iopub.execute_input":"2021-11-24T03:49:36.679122Z","iopub.status.idle":"2021-11-24T03:49:36.715649Z","shell.execute_reply.started":"2021-11-24T03:49:36.679071Z","shell.execute_reply":"2021-11-24T03:49:36.713676Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Set parameters\nIMAGE_SIZE = (256, 256)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:49:36.717636Z","iopub.execute_input":"2021-11-24T03:49:36.718067Z","iopub.status.idle":"2021-11-24T03:49:36.723696Z","shell.execute_reply.started":"2021-11-24T03:49:36.718023Z","shell.execute_reply":"2021-11-24T03:49:36.722372Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 2. Create DataFrame","metadata":{}},{"cell_type":"code","source":"mask_files = glob('../input/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\ntrain_files = [file.replace('_mask', '') for file in mask_files]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def diagnosis(mask_path):\n    value = np.max(cv2.imread(mask_path))\n    return '1' if value > 0 else '0'\ndf = pd.DataFrame({\"image_path\": train_files,\n                   \"mask_path\": mask_files,\n                  \"diagnosis\":[diagnosis(x) for x in mask_files]})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:50:09.428743Z","iopub.execute_input":"2021-11-24T03:50:09.429134Z","iopub.status.idle":"2021-11-24T03:50:14.835721Z","shell.execute_reply.started":"2021-11-24T03:50:09.429101Z","shell.execute_reply":"2021-11-24T03:50:14.834433Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Plot\nax = df.diagnosis.value_counts().plot(kind='bar',\n                                      stacked=True,\n                                      figsize=(10, 6),\n                                     color=[\"violet\", \"lightseagreen\"])\n\n\nax.set_xticklabels([\"Positive\", \"Negative\"], rotation=45, fontsize=12);\nax.set_ylabel('Total Images', fontsize = 12)\nax.set_title(\"Distribution of data grouped by diagnosis\",fontsize = 18, y=1.05)\n\n# Annotate\nfor i, rows in enumerate(df.diagnosis.value_counts().values):\n    ax.annotate(int(rows), xy=(i, rows-12), \n                rotation=0, color=\"white\", \n                ha=\"center\", verticalalignment='bottom', \n                fontsize=15, fontweight=\"bold\")\n    \nax.text(1.2, 2550, f\"Total {len(df)} images\", size=15,\n        color=\"black\",\n         ha=\"center\", va=\"center\",\n         bbox=dict(boxstyle=\"round\",\n                   fc=(\"lightblue\"),\n                   ec=(\"black\"),\n                   )\n         );","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:50:57.173655Z","iopub.execute_input":"2021-11-24T03:50:57.174031Z","iopub.status.idle":"2021-11-24T03:50:57.434616Z","shell.execute_reply.started":"2021-11-24T03:50:57.174001Z","shell.execute_reply":"2021-11-24T03:50:57.433441Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Visualize MRI with Mask","metadata":{}},{"cell_type":"code","source":"df_positive = df[df['diagnosis']=='1'].sample(5).values\ndf_negative = df[df['diagnosis']=='0'].sample(5).values\n\ndef show_data(df, positive=True):\n    images = []\n    masks = []\n    for data in df:\n        img = cv2.imread(data[0])\n        mask = cv2.imread(data[1])\n        images.append(img)\n        masks.append(mask)\n    images = np.hstack(np.array(images))\n    masks = np.hstack(np.array(masks))\n    \n    fig = plt.figure(figsize=(25,25))\n    if positive:\n        grid = ImageGrid(fig, 111, nrows_ncols=(3,1), axes_pad=0.5)\n    else:\n        grid = ImageGrid(fig, 111, nrows_ncols=(2,1), axes_pad=0.5)\n    grid[0].imshow(images)\n    grid[0].set_title('Images', fontsize=15)\n    grid[0].axis('off')\n    grid[1].imshow(masks)\n    grid[1].set_title('Masks', fontsize=15)\n    grid[1].axis('off')\n    if positive:\n        grid[2].imshow(images)\n        grid[2].imshow(masks, alpha=0.4)\n        grid[2].set_title('Brain MRI with mask', fontsize=15)\n        grid[2].axis('off')\n        \nshow_data(df_positive)\nshow_data(df_negative, positive=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:51:26.288263Z","iopub.execute_input":"2021-11-24T03:51:26.288660Z","iopub.status.idle":"2021-11-24T03:51:29.370215Z","shell.execute_reply.started":"2021-11-24T03:51:26.288628Z","shell.execute_reply":"2021-11-24T03:51:29.369177Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Split data into Train, Validation and Test Set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ndf_train, df_test = train_test_split(df, test_size=0.15)\ndf_train, df_val = train_test_split(df_train, test_size=0.15)\nprint(df_train.values.shape)\nprint(df_val.values.shape)\nprint(df_test.values.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:51:35.458657Z","iopub.execute_input":"2021-11-24T03:51:35.459011Z","iopub.status.idle":"2021-11-24T03:51:36.117245Z","shell.execute_reply.started":"2021-11-24T03:51:35.458979Z","shell.execute_reply":"2021-11-24T03:51:36.116215Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## 3. U-Net Model","metadata":{}},{"cell_type":"markdown","source":"### Data Generator, Data Augmentation and Adjust Data","metadata":{}},{"cell_type":"code","source":"def train_generator(data_frame, batch_size, aug_dict,\n        image_color_mode=\"rgb\",\n        mask_color_mode=\"grayscale\",\n        image_save_prefix=\"image\",\n        mask_save_prefix=\"mask\",\n        save_to_dir=None,\n        target_size=(256,256),\n        seed=1):\n\n    image_datagen = ImageDataGenerator(**aug_dict)\n    mask_datagen = ImageDataGenerator(**aug_dict)\n    \n    image_generator = image_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"image_path\",\n        class_mode = None,\n        color_mode = image_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = image_save_prefix,\n        seed = seed)\n\n    mask_generator = mask_datagen.flow_from_dataframe(\n        data_frame,\n        x_col = \"mask_path\",\n        class_mode = None,\n        color_mode = mask_color_mode,\n        target_size = target_size,\n        batch_size = batch_size,\n        save_to_dir = save_to_dir,\n        save_prefix  = mask_save_prefix,\n        seed = seed)\n\n    train_gen = zip(image_generator, mask_generator)\n    \n    for (img, mask) in train_gen:\n        img, mask = adjust_data(img, mask)\n        yield (img,mask)\n\ndef adjust_data(img,mask):\n    img = img / 255.\n    mask = mask / 255.\n    mask[mask > 0.5] = 1\n    mask[mask <= 0.5] = 0\n    \n    return (img, mask)","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:51:38.646455Z","iopub.execute_input":"2021-11-24T03:51:38.646838Z","iopub.status.idle":"2021-11-24T03:51:38.657279Z","shell.execute_reply.started":"2021-11-24T03:51:38.646808Z","shell.execute_reply":"2021-11-24T03:51:38.655974Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Segmentation Quality Metric","metadata":{}},{"cell_type":"markdown","source":"![](https://www.pyimagesearch.com/wp-content/uploads/2016/09/iou_equation.png)![](https://d3i71xaburhd42.cloudfront.net/8575e8beef47bd2880c92f54a749f933db983e56/2-Table1-1.png)","metadata":{}},{"cell_type":"code","source":"smooth=100\n\ndef dice_coef(y_true, y_pred):\n    y_true = K.flatten(y_true)\n    y_pred = K.flatten(y_pred)\n    intersection = K.sum(y_true * y_pred)\n    union = K.sum(y_true) + K.sum(y_pred)\n    return (2.0 * intersection + smooth) / (union + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n\ndef iou(y_true, y_pred):\n    intersection = K.sum(y_true * y_pred)\n    sum_ = K.sum(y_true + y_pred)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return jac","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:51:41.454300Z","iopub.execute_input":"2021-11-24T03:51:41.454708Z","iopub.status.idle":"2021-11-24T03:51:41.463657Z","shell.execute_reply.started":"2021-11-24T03:51:41.454676Z","shell.execute_reply":"2021-11-24T03:51:41.462289Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Define UNet Model","metadata":{}},{"cell_type":"markdown","source":"![](https://i.imgur.com/lKZGO0C.png)","metadata":{}},{"cell_type":"code","source":"def unet(input_size=(256,256,3)):\n    inputs = Input(input_size)\n    \n    conv1 = Conv2D(64, (3, 3), padding='same')(inputs)\n    bn1 = Activation('relu')(conv1)\n    conv1 = Conv2D(64, (3, 3), padding='same')(bn1)\n    bn1 = BatchNormalization(axis=3)(conv1)\n    bn1 = Activation('relu')(bn1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n\n    conv2 = Conv2D(128, (3, 3), padding='same')(pool1)\n    bn2 = Activation('relu')(conv2)\n    conv2 = Conv2D(128, (3, 3), padding='same')(bn2)\n    bn2 = BatchNormalization(axis=3)(conv2)\n    bn2 = Activation('relu')(bn2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n\n    conv3 = Conv2D(256, (3, 3), padding='same')(pool2)\n    bn3 = Activation('relu')(conv3)\n    conv3 = Conv2D(256, (3, 3), padding='same')(bn3)\n    bn3 = BatchNormalization(axis=3)(conv3)\n    bn3 = Activation('relu')(bn3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(bn3)\n\n    conv4 = Conv2D(512, (3, 3), padding='same')(pool3)\n    bn4 = Activation('relu')(conv4)\n    conv4 = Conv2D(512, (3, 3), padding='same')(bn4)\n    bn4 = BatchNormalization(axis=3)(conv4)\n    bn4 = Activation('relu')(bn4)\n    pool4 = MaxPooling2D(pool_size=(2, 2))(bn4)\n\n    conv5 = Conv2D(1024, (3, 3), padding='same')(pool4)\n    bn5 = Activation('relu')(conv5)\n    conv5 = Conv2D(1024, (3, 3), padding='same')(bn5)\n    bn5 = BatchNormalization(axis=3)(conv5)\n    bn5 = Activation('relu')(bn5)\n\n    up6 = concatenate([Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bn5), conv4], axis=3)\n    conv6 = Conv2D(512, (3, 3), padding='same')(up6)\n    bn6 = Activation('relu')(conv6)\n    conv6 = Conv2D(512, (3, 3), padding='same')(bn6)\n    bn6 = BatchNormalization(axis=3)(conv6)\n    bn6 = Activation('relu')(bn6)\n\n    up7 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(bn6), conv3], axis=3)\n    conv7 = Conv2D(256, (3, 3), padding='same')(up7)\n    bn7 = Activation('relu')(conv7)\n    conv7 = Conv2D(256, (3, 3), padding='same')(bn7)\n    bn7 = BatchNormalization(axis=3)(conv7)\n    bn7 = Activation('relu')(bn7)\n\n    up8 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(bn7), conv2], axis=3)\n    conv8 = Conv2D(128, (3, 3), padding='same')(up8)\n    bn8 = Activation('relu')(conv8)\n    conv8 = Conv2D(128, (3, 3), padding='same')(bn8)\n    bn8 = BatchNormalization(axis=3)(conv8)\n    bn8 = Activation('relu')(bn8)\n\n    up9 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(bn8), conv1], axis=3)\n    conv9 = Conv2D(64, (3, 3), padding='same')(up9)\n    bn9 = Activation('relu')(conv9)\n    conv9 = Conv2D(64, (3, 3), padding='same')(bn9)\n    bn9 = BatchNormalization(axis=3)(conv9)\n    bn9 = Activation('relu')(bn9)\n\n    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(bn9)\n\n    return Model(inputs=[inputs], outputs=[conv10])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:51:44.686981Z","iopub.execute_input":"2021-11-24T03:51:44.687441Z","iopub.status.idle":"2021-11-24T03:51:44.713469Z","shell.execute_reply.started":"2021-11-24T03:51:44.687408Z","shell.execute_reply":"2021-11-24T03:51:44.712012Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## 4. Training","metadata":{}},{"cell_type":"code","source":"# Set parameters\nEPOCHS = 150\nBATCH_SIZE = 32\nlearning_rate = 1e-4","metadata":{"execution":{"iopub.status.busy":"2021-11-24T03:51:47.666238Z","iopub.execute_input":"2021-11-24T03:51:47.666674Z","iopub.status.idle":"2021-11-24T03:51:47.671775Z","shell.execute_reply.started":"2021-11-24T03:51:47.666642Z","shell.execute_reply":"2021-11-24T03:51:47.670605Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_generator_args = dict(rotation_range=0.1,\n                            width_shift_range=0.05,\n                            height_shift_range=0.05,\n                            shear_range=0.05,\n                            zoom_range=0.05,\n                            horizontal_flip=True,\n                            vertical_flip=True,\n                            fill_mode='nearest')\ntrain_gen = train_generator(df_train, BATCH_SIZE,\n                                train_generator_args,\n                                target_size=IMAGE_SIZE)\n    \nval_gen = train_generator(df_val, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\n    \nmodel = unet(input_size=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n\n\n\nopt = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\nmodel.compile(optimizer=opt, loss=bce_dice_loss, metrics=[iou, dice_coef])\n\ncallbacks = [ModelCheckpoint('unet_brainMRI_seg.hdf5', verbose=0, save_best_only=True),\n            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n            EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=15)]\n\nhistory = model.fit(train_gen,\n                    steps_per_epoch=len(df_train) / BATCH_SIZE, \n                    epochs=EPOCHS, \n                    callbacks=callbacks,\n                    validation_data = val_gen,\n                    validation_steps=len(df_val) / BATCH_SIZE)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-11-24T03:51:53.578012Z","iopub.execute_input":"2021-11-24T03:51:53.578426Z","iopub.status.idle":"2021-11-24T06:04:25.012196Z","shell.execute_reply.started":"2021-11-24T03:51:53.578372Z","shell.execute_reply":"2021-11-24T06:04:25.010897Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the model performance","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,15))\nplt.subplot(3,1,1)\nplt.plot(model.history.history['loss'], 'b-', label='train_loss')\nplt.plot(model.history.history['val_loss'], 'r-', label='val_loss')\nplt.legend(loc='best')\nplt.title('Loss')\n\nplt.subplot(3,1,2)\nplt.plot(model.history.history['iou'], 'b-', label='train_iou')\nplt.plot(model.history.history['val_iou'], 'r-', label='val_iou')\nplt.legend(loc='best')\nplt.title('IoU')\n\nplt.subplot(3,1,3)\nplt.plot(model.history.history['dice_coef'], 'b-', label='train_dice_coef')\nplt.plot(model.history.history['val_dice_coef'], 'r-', label='val_dice_coef')\nplt.legend(loc='best')\nplt.title('Dice Coef')","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:05:57.107828Z","iopub.execute_input":"2021-11-24T06:05:57.108248Z","iopub.status.idle":"2021-11-24T06:05:57.806941Z","shell.execute_reply.started":"2021-11-24T06:05:57.108201Z","shell.execute_reply":"2021-11-24T06:05:57.805614Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## 5. Evaluate the model","metadata":{}},{"cell_type":"code","source":"test_gen = train_generator(df_test, BATCH_SIZE,\n                                dict(),\n                                target_size=IMAGE_SIZE)\nresults = model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\nprint(\"Test IOU: \",results[1])\nprint(\"Test Dice Coefficent: \",results[2])","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:06:04.120583Z","iopub.execute_input":"2021-11-24T06:06:04.120945Z","iopub.status.idle":"2021-11-24T06:06:16.252303Z","shell.execute_reply.started":"2021-11-24T06:06:04.120913Z","shell.execute_reply":"2021-11-24T06:06:16.251129Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### Visualize the Result","metadata":{}},{"cell_type":"code","source":"for i in range(30):\n    index=np.random.randint(1,len(df_test.index))\n    img = cv2.imread(df_test['image_path'].iloc[index])\n    img = cv2.resize(img ,IMAGE_SIZE)\n    img = img / 255\n    img = img[np.newaxis, :, :, :]\n    pred=model.predict(img)\n\n    plt.figure(figsize=(12,12))\n    plt.subplot(1,3,1)\n    plt.imshow(np.squeeze(img))\n    plt.title('Original Image')\n    plt.subplot(1,3,2)\n    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])))\n    plt.title('Original Mask')\n    plt.subplot(1,3,3)\n    plt.imshow(np.squeeze(pred) > .5)\n    plt.title('Prediction')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:06:16.254760Z","iopub.execute_input":"2021-11-24T06:06:16.255276Z","iopub.status.idle":"2021-11-24T06:06:34.233033Z","shell.execute_reply.started":"2021-11-24T06:06:16.255220Z","shell.execute_reply":"2021-11-24T06:06:34.231608Z"},"trusted":true},"execution_count":21,"outputs":[]}]}